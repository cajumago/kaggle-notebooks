{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eae480cf",
   "metadata": {},
   "source": [
    "# Linear Regression using XGBoost\n",
    "\n",
    "- `Pandas`, `Scikit-learn` for cleaning data\n",
    "- `Matplotlib`, `Seaborn` for some basic visualizations\n",
    "- `Scikit-learn` for scaling\n",
    "- `XGBoost` for predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb52f1c7",
   "metadata": {},
   "source": [
    "### 1. Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f567ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_squared_log_error\n",
    "import category_encoders as ce\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e676f2",
   "metadata": {},
   "source": [
    "### 2. Loading the `train` dataset\n",
    "Before starting on any task, it is useful to get more familiar with your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5dfbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv').set_index('Id')\n",
    "print ('The shape of df_train is: ', df_train.shape)\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d4ed3e",
   "metadata": {},
   "source": [
    "- Target values are stored in a Numpy scalar `y_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef2eee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_raw = np.array(df_train['SalePrice'])\n",
    "# print y_train_raw\n",
    "print(f\"y_train_raw Shape: {y_train_raw.shape}, y_train_raw Type: {type(y_train_raw)})\")\n",
    "print(\"First element of y_train_raw are:\\n\", y_train_raw[:])\n",
    "print(\"Dimension of y_train_raw:\", y_train_raw.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86105eec",
   "metadata": {},
   "source": [
    "### 3. Visualize your data\n",
    "* Correlated columns with `SalePrice`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0349d86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_train.corr()\n",
    "corr.sort_values(['SalePrice'], ascending=False, inplace=True)\n",
    "corr.SalePrice.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d22dd4",
   "metadata": {},
   "source": [
    "- It is often useful to understand the data by visualizing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eec034",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,3, figsize=(20,15), sharey=True)\n",
    "\n",
    "plt.title('OverallQual')\n",
    "sns.scatterplot(ax=axes[0,0], data=df_train, x='OverallQual', y='SalePrice', color='b')\n",
    "plt.title('GrLivArea')\n",
    "sns.scatterplot(ax=axes[0,1], data=df_train, x='GrLivArea', y='SalePrice', color='g')\n",
    "plt.title('GarageCars')\n",
    "sns.scatterplot(ax=axes[0,2], data=df_train, x='GarageCars', y='SalePrice', color='b')\n",
    "plt.title('GarageArea')\n",
    "sns.scatterplot(ax=axes[1,0], data=df_train, x='GarageArea', y='SalePrice', color='g')\n",
    "plt.title('TotalBsmtSF')\n",
    "sns.scatterplot(ax=axes[1,1], data=df_train, x='TotalBsmtSF', y='SalePrice', color='b')\n",
    "plt.title('1stFlrSF')\n",
    "sns.scatterplot(ax=axes[1,2], data=df_train, x='1stFlrSF', y='SalePrice', color='g')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878860a0",
   "metadata": {},
   "source": [
    "* Histogram `['SalePrice']` on `train` set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5277a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['SalePrice'].hist(bins = 50);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3389b3",
   "metadata": {},
   "source": [
    "### 4. Loading the `test` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c459f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test.csv').set_index('Id')\n",
    "print ('The shape of df_test is: ', df_test.shape)\n",
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6cb879",
   "metadata": {},
   "source": [
    "### 5. Scaling and category encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9274038",
   "metadata": {},
   "source": [
    "- Choosing numeric features on `train` set and leaving out `SalePrice`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41755d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop('SalePrice', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4fad6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_numeric_features = make_column_selector(dtype_include=np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6aeceb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numeric_features_train = select_numeric_features(df_train)\n",
    "\n",
    "print(f'N numeric_features_train: {len(numeric_features_train)} \\n')\n",
    "print(', '.join(numeric_features_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604df294",
   "metadata": {},
   "source": [
    "- Visualizing numeric features on `test` set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79d0b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features_test = select_numeric_features(df_test)\n",
    "\n",
    "print(f'N numeric_features_test: {len(numeric_features_test)} \\n')\n",
    "print(', '.join(numeric_features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddc6dee",
   "metadata": {},
   "source": [
    "#### Impute missing features values using a descriptive statistic `mean`, and normalize numeric features using `StandardScaler`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda494c5",
   "metadata": {},
   "source": [
    "- `train` & `test` sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed2fe07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.fillna(np.nan, inplace=True)\n",
    "df_test.fillna(np.nan, inplace=True)\n",
    "\n",
    "numeric_pipeline = make_pipeline(SimpleImputer(strategy='mean'), StandardScaler())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f946452b",
   "metadata": {},
   "source": [
    "##### Cardinality categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0b774b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_object = df_train.select_dtypes(include=\"object\")\n",
    "df_train_object.nunique().plot.bar(figsize=(20,8))\n",
    "plt.ylabel('Number of unique categories')\n",
    "plt.xlabel('Variables')\n",
    "plt.title('Cardinality check')\n",
    "plt.axhline(y = 10, color= 'r', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b47140",
   "metadata": {},
   "source": [
    "#### Categorical with moderate-to-low cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b99728",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_OH_CARDINALITY = 10\n",
    "\n",
    "def select_oh_features(df):\n",
    "    \n",
    "    hc_features =\\\n",
    "        df\\\n",
    "        .select_dtypes(['object', 'category'])\\\n",
    "        .apply(lambda col: col.nunique())\\\n",
    "        .loc[lambda x: x <= MAX_OH_CARDINALITY]\\\n",
    "        .index\\\n",
    "        .tolist()\n",
    "        \n",
    "    return hc_features\n",
    "\n",
    "oh_features = select_oh_features(df_train)\n",
    "\n",
    "print(f'N oh_features: {len(oh_features)} \\n')\n",
    "print(', '.join(oh_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d173ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_pipeline = make_pipeline(SimpleImputer(strategy='constant'), OneHotEncoder(handle_unknown='ignore'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd39092",
   "metadata": {},
   "source": [
    "#### Categorical with high cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4cba56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_hc_features(df):\n",
    "    \n",
    "    hc_features =\\\n",
    "        df\\\n",
    "        .select_dtypes(['object', 'category'])\\\n",
    "        .apply(lambda col: col.nunique())\\\n",
    "        .loc[lambda x: x > MAX_OH_CARDINALITY]\\\n",
    "        .index\\\n",
    "        .tolist()\n",
    "        \n",
    "    return hc_features\n",
    "\n",
    "\n",
    "hc_features = select_hc_features(df_train)\n",
    "\n",
    "print(f'N hc_features: {len(hc_features)} \\n')\n",
    "print(', '.join(hc_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b872bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_pipeline = make_pipeline(ce.GLMMEncoder())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe77360",
   "metadata": {},
   "source": [
    "#### Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7e61dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_transformer = ColumnTransformer(transformers = \n",
    "                                       [('numeric_pipeline', numeric_pipeline, select_numeric_features),\n",
    "                                        ('oh_pipeline', oh_pipeline, select_oh_features),\n",
    "                                        ('hc_pipeline', hc_pipeline, select_hc_features)],\n",
    "                      remainder='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0909a7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trsf = column_transformer.fit_transform(df_train, y_train_raw)\n",
    "X_test_trsf = column_transformer.transform(df_test)\n",
    "\n",
    "print(X_train_trsf.shape)\n",
    "print(X_test_trsf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dfd522",
   "metadata": {},
   "source": [
    "- Checking `train` set transformed as `numpy.ndarray`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09745474",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(np.isnan(X_train_trsf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889d4fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train_trsf Type     :\", type(X_train_trsf))\n",
    "print(f\"X_train_trsf Shape    : {X_train_trsf.shape}\")\n",
    "print(\"X_train_trsf Dimension:\", X_train_trsf.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85636aa9",
   "metadata": {},
   "source": [
    "Normalize and encoder `train` examples are stored in a Numpy matriz `X_train_trsf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60618109",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"First element of X_train_trsf are:\\n\", X_train_trsf[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6767a0d",
   "metadata": {},
   "source": [
    "- Checking `test` set transformed as `numpy.ndarray`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04807ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(np.isnan(X_test_trsf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b3fe2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_test_trsf Type     :\", type(X_test_trsf))\n",
    "print(f\"X_test_trsf Shape    : {X_test_trsf.shape}\")\n",
    "print(\"X_test_trsf Dimension:\", X_test_trsf.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4133de56",
   "metadata": {},
   "source": [
    "Normalize and encoder `test` examples are stored in a Numpy matriz `X_test_trsf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c5be20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"First element of X_test_trsf are:\\n\", X_test_trsf[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1429ea",
   "metadata": {},
   "source": [
    "### 6. Fit the model with `XGBoost`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652fc6e5",
   "metadata": {},
   "source": [
    "- Separate data into *training* and *validation* sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e91b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_trsf, y_train_raw, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db87667a",
   "metadata": {},
   "source": [
    "- Shape and Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed887ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"X_train Shape    : {X_train.shape},| y_train Shape    : {y_train.shape}\")\n",
    "print(\"X_train Dimension:\", X_train.ndim, \"          | y_train Dimension:\", y_train.ndim)\n",
    "print(f\"X_valid Shape    : {X_valid.shape}, | y_valid Shape    : {y_valid.shape}\")\n",
    "print(\"X_valid Dimension:\", X_valid.ndim, \"          | y_valid Dimension:\", y_valid.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9083fb",
   "metadata": {},
   "source": [
    "#### `XGBRegressor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3772f0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0 = xgb.XGBRegressor()\n",
    "model_0.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309e6c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_0 = model_0.predict(X_valid)\n",
    "\n",
    "print(\"R2 Score                           : \" + str(r2_score(y_valid, predictions_0)))\n",
    "print(\"Mean Absolute Error                : \" + str(mean_absolute_error(y_valid, predictions_0)))\n",
    "print(\"Mean Square Error                  : \" + str(mean_squared_error(y_valid, predictions_0)))\n",
    "print(\"Mean Squared Logarithmic Error     : \" + str(mean_squared_log_error(y_valid, predictions_0)))\n",
    "print(\"Root Mean Square Error             : \" + str(np.sqrt(mean_squared_error(y_valid, predictions_0))))\n",
    "print(\"Root Mean Squared Logarithmic Error: \" + str(np.sqrt(mean_squared_log_error(y_valid, predictions_0))))\n",
    "\n",
    "# ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e41b8d6",
   "metadata": {},
   "source": [
    "- Parameter Tuning 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7908a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = xgb.XGBRegressor(n_estimators=500)\n",
    "model_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23c748c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_1 = model_1.predict(X_valid)\n",
    "\n",
    "print(\"R2 Score                           : \" + str(r2_score(y_valid, predictions_1)))\n",
    "print(\"Mean Absolute Error                : \" + str(mean_absolute_error(y_valid, predictions_1)))\n",
    "print(\"Mean Square Error                  : \" + str(mean_squared_error(y_valid, predictions_1)))\n",
    "print(\"Mean Squared Logarithmic Error     : \" + str(mean_squared_log_error(y_valid, predictions_1)))\n",
    "print(\"Root Mean Square Error             : \" + str(np.sqrt(mean_squared_error(y_valid, predictions_1))))\n",
    "print(\"Root Mean Squared Logarithmic Error: \" + str(np.sqrt(mean_squared_log_error(y_valid, predictions_1))))\n",
    "\n",
    "# ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af08113e",
   "metadata": {},
   "source": [
    "- Parameter Tuning 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c6477d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = xgb.XGBRegressor(n_estimators=1000)\n",
    "model_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d900262b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_2 = model_2.predict(X_valid)\n",
    "\n",
    "print(\"R2 Score                           : \" + str(r2_score(y_valid, predictions_2)))\n",
    "print(\"Mean Absolute Error                : \" + str(mean_absolute_error(y_valid, predictions_2)))\n",
    "print(\"Mean Square Error                  : \" + str(mean_squared_error(y_valid, predictions_2)))\n",
    "print(\"Mean Squared Logarithmic Error     : \" + str(mean_squared_log_error(y_valid, predictions_2)))\n",
    "print(\"Root Mean Square Error             : \" + str(np.sqrt(mean_squared_error(y_valid, predictions_2))))\n",
    "print(\"Root Mean Squared Logarithmic Error: \" + str(np.sqrt(mean_squared_log_error(y_valid, predictions_2))))\n",
    "\n",
    "# ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb44da4e",
   "metadata": {},
   "source": [
    "- Parameter Tuning 3\n",
    "\n",
    ">**GridSearchCV**: Best parameters: `(n_estimators=500, max_depth=5, colsample_bylevel=0.4, learning_rate=3.0e-2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8e6d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = xgb.XGBRegressor(n_estimators=500, max_depth=5, colsample_bylevel=0.4, learning_rate=3.0e-2)\n",
    "model_3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb6c6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_3 = model_3.predict(X_valid)\n",
    "\n",
    "print(\"R2 Score                           : \" + str(r2_score(y_valid, predictions_3)))\n",
    "print(\"Mean Absolute Error                : \" + str(mean_absolute_error(y_valid, predictions_3)))\n",
    "print(\"Mean Square Error                  : \" + str(mean_squared_error(y_valid, predictions_3)))\n",
    "print(\"Mean Squared Logarithmic Error     : \" + str(mean_squared_log_error(y_valid, predictions_3)))\n",
    "print(\"Root Mean Square Error             : \" + str(np.sqrt(mean_squared_error(y_valid, predictions_3))))\n",
    "print(\"Root Mean Squared Logarithmic Error: \" + str(np.sqrt(mean_squared_log_error(y_valid, predictions_3))))\n",
    "\n",
    "# ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23fb565",
   "metadata": {},
   "source": [
    "* Outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b0cc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(predictions_3 < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8439f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of predictions_3:\", predictions_3.shape)\n",
    "print(\"Dimension of predictions_3:\", predictions_3.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5b6006",
   "metadata": {},
   "source": [
    "### 12. Make predictions on `test` set\n",
    "Make predictions using best model `model_3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6af95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = model_3.predict(X_test_trsf)\n",
    "\n",
    "print(\"R2 Score                           : \" + str(r2_score(y_train_raw[:1459,], predictions_test)))\n",
    "print(\"Mean Absolute Error                : \" + str(mean_absolute_error(y_train_raw[:1459,], predictions_test)))\n",
    "print(\"Mean Square Error                  : \" + str(mean_squared_error(y_train_raw[:1459,], predictions_test)))\n",
    "print(\"Mean Squared Logarithmic Error     : \" + str(mean_squared_log_error(y_train_raw[:1459,], predictions_test)))\n",
    "print(\"Root Mean Square Error             : \" + str(np.sqrt(mean_squared_error(y_train_raw[:1459,], predictions_test))))\n",
    "print(\"Root Mean Squared Logarithmic Error: \" + str(np.sqrt(mean_squared_log_error(y_train_raw[:1459,], predictions_test))))\n",
    "\n",
    "# ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd58f82b",
   "metadata": {},
   "source": [
    "### Back to Pandas for submitting predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13352e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(dict(Id=df_test.index, SalePrice=predictions_test))\n",
    "submission.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697b662e",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6d5ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = submission.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf33fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission.to_csv('submission.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7e987a",
   "metadata": {},
   "source": [
    "## Acknowledgments\n",
    "\n",
    "- Machine Learning Specialization offered jointly by DeepLearning.AI and Stanford University on Coursera.\n",
    "- The housing data was derived from **Kaggle** [House Prices - Advanced Regression Techniques](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/overview).\n",
    "- Category Encoder: Scikit-Learn ColumnTransformer approach from [Kyle Gilde](https://www.kaggle.com/code/kylegilde/building-columntransformers-dynamically) on **Kaggle**\n",
    "\n",
    ">Let me know if you have any recommendations.  Thanks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa37a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
